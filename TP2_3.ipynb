{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYND2HA3sAKwtT3E1DvbJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farshidehkordi/Homework2_AI/blob/main/TP2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rc7J3u7J7IU",
        "outputId": "9fc3fffb-4cad-4b4c-a3ab-2803d864c8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in the current directory\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1cvBg4dKNrz",
        "outputId": "db77d4b2-a26f-47f4-d6ad-4bada1e0ec45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Classes are :\n",
        "# 0 - Boston\n",
        "# 1 - London\n",
        "# 2 - Montreal\n",
        "# 3 - Paris\n",
        "# 4 - Quebec\n",
        "\n",
        "# Define the network architecture (fully connected using ReLU) :\n",
        "class ModifiedDropoutNetwork(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ModifiedDropoutNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 256)  # Adjust the input size of fc1\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(p=0.5)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(p=0.5)\n",
        "        self.fc4 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 5\n",
        "batch_size = 64\n",
        "initial_learning_rate = 0.001\n",
        "patience = 5\n",
        "\n",
        "# Load dataset\n",
        "train_data_path = '/content/drive/MyDrive/glo-7030-ou-suis-je-h2024/train/'\n",
        "test_data_path = '/content/drive/MyDrive/glo-7030-ou-suis-je-h2024/test/'\n",
        "\n",
        "# Define the transform\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class SingleClassTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_names = sorted(os.listdir(root_dir))  # Assuming the images are named as '00000.jpg', '00001.jpg', etc.\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_names[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, 0  # Assigning the class label as 0 for all images in the test dataset\n",
        "\n",
        "# Splitting the training dataset into train and validation sets\n",
        "train_dataset = datasets.ImageFolder(root=train_data_path, transform=data_transform)\n",
        "valid_size = int(0.2 * len(train_dataset))  # For example, you can use 20% of the training data for validation\n",
        "train_size = len(train_dataset) - valid_size  # Adjust train_size to exclude validation set\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
        "\n",
        "# Data loader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=SingleClassTestDataset(root_dir=test_data_path, transform=data_transform), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model\n",
        "model = ModifiedDropoutNetwork(num_classes=5).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=initial_learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=patience, factor=0.5)\n",
        "\n",
        "# Training the model\n",
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "train_accuracy_list = []\n",
        "valid_accuracy_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_accuracy = 100 * correct / total\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    valid_accuracy_list.append(valid_accuracy)\n",
        "\n",
        "    # Print training and validation loss\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Train Acc: {train_accuracy:.2f}, Valid Acc: {valid_accuracy:.2f}')\n",
        "\n",
        "    # Step with the scheduler\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}')\n",
        "\n",
        "# Get and print the last learning rate\n",
        "last_lr = optimizer.param_groups[0]['lr']\n",
        "print(f'Last learning rate: {last_lr}')\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_list, '-o', label='Train Loss')\n",
        "plt.plot(valid_loss_list, '-o', label='Valid Loss')\n",
        "plt.title('Training and Validation Loss Per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the training and validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracy_list, '-o', label='Train Accuracy')\n",
        "plt.plot(valid_accuracy_list, '-o', label='Valid Accuracy')\n",
        "plt.title('Training and Validation Accuracy Per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rFTul-EwN6kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fca7f8-165c-476e-e764-b9b70365f6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Train Loss: 1.6861, Valid Loss: 1.5558, Train Acc: 23.16, Valid Acc: 25.61\n",
            "Epoch [2/5], Train Loss: 1.5616, Valid Loss: 1.5543, Train Acc: 28.03, Valid Acc: 28.54\n"
          ]
        }
      ]
    }
  ]
}